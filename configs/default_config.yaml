# Default Configuration
# 
# Access in code:
#   from configs.loader import load_config, Config
#   cfg = Config(load_config())

# Data paths
data:
  raw_dir: "data/raw"
  processed_dir: "data/processed"
  augmented_dir: "data/augmented"
  splits_dir: "data/splits"
  # Default dataset name (optional). If present, tools may look for
  # <raw_dir>/<dataset_name>/metadata.json
  dataset_name: "van_gogh_dataset"

# CV Enhancement
cv_enhancement:
  preprocessing:
    normalize: true             # -> CVEnhancementAPI.preprocess(..., normalize=True)
  augmentation:
    enabled: false               # -> CVEnhancementAPI.augment(..., enabled=True)
  filtering:
    enabled: true              # -> CVEnhancementAPI.apply_filter(..., enabled=True/False)
  filters: []                  # -> list of filter names used by CVEnhancementAPI.apply_filter

# Training
nn_training:
  model:
    name: null                  # -> NNTrainingAPI.create_model(config) may use `name` to pick architecture
  training:
    epochs: 100                 # -> NNTrainingAPI.train(..., epochs=100)
    batch_size: 32              # -> NNTrainingAPI.train(..., batch_size=32)
    learning_rate: 0.001        # -> NNTrainingAPI.train(..., learning_rate=0.001)
    device: "cpu"               # -> CLI `--device` or `nn_training.training.device`
    seed: null                  # -> CLI `--seed` or `nn_training.training.seed`
  checkpoints:
    dir: "experiments/checkpoints"  # -> default path for NNTrainingAPI.save_checkpoint
    save_frequency: 10          # -> CLI `--save-every` or `nn_training.checkpoints.save_frequency`

# Validation
validation:
  metrics: ["accuracy", "precision", "recall", "f1"]  # -> ValidationAPI.compute_metrics(..., metrics=[...])
  visualization:
    save_plots: true           # -> ValidationAPI.plot_results(..., save when True)
    output_dir: "experiments/results"  # -> ValidationAPI.plot_results(..., save_path=output_dir)
  reports:
    output_dir: "validation/reports"  # -> used by report generation (optional)

# Experiments
experiments:
  logs_dir: "experiments/logs"  # -> training logs path
  results_dir: "experiments/results"  # -> overall results output

# Pipeline
pipeline:

  dataloader: "data.dataloader:DataLoader"    # dotted path to DataLoader
  dataloader_config:
    # If provided, the loader will look under <data.raw_dir>/<dataset_name>
    dataset_name: "van_gogh_dataset"
    metadata_file: "metadata.json"
    # Strategy for handling class imbalance: null | "oversample" | "class_weights"
    balance_strategy: "class_weights"
    stratify_splits: true
  cv_enhancer: null           # dotted path to CVEnhancer (e.g. mypkg.cv.CVEnhancer)
  trainer: null               # dotted path to Trainer (e.g. mypkg.trainers.MyTrainer)
  validator: null             # dotted path to Validator (e.g. mypkg.validation.MyValidator)
  steps: ["prepare", "train", "evaluate"]  # which steps to run by default
